{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* 1. LLM (Large Language Model)\n",
        "\n"
      ],
      "metadata": {
        "id": "0k9NHVHm0ZpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0IR7gt20QBu"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = client.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message[\"content\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. RAG (Retrieval-Augmented Generation) Example\n",
        "Using LangChain with OpenAI + FAISS vector DB."
      ],
      "metadata": {
        "id": "SO5OOXSE0iwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Load document\n",
        "loader = TextLoader(\"example_doc.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Split into chunks\n",
        "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "docs = splitter.split_documents(documents)\n",
        "\n",
        "# Create vector store\n",
        "embedding = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(docs, embedding)\n",
        "\n",
        "# RetrievalQA Chain\n",
        "retriever = db.as_retriever()\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "# Ask question\n",
        "result = qa_chain.run(\"What does the document say about RAG?\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "VM7w-Koc0Xw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. AI Agent Example (LangChain Tool Use)\n",
        "Agent that uses a calculator tool"
      ],
      "metadata": {
        "id": "rElOW0uk0luF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "def simple_calculator(query: str) -> str:\n",
        "    return str(eval(query))\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=simple_calculator,\n",
        "        description=\"Useful for math calculations\"\n",
        "    )\n",
        "]\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
        "\n",
        "response = agent.run(\"What is (4 * 3) + 2?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "kke0tnqw0oYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Agentic AI Example (Multi-Agent via AutoGen)\n",
        "Using Microsoftâ€™s AutoGen framework to show collaboration between two agents."
      ],
      "metadata": {
        "id": "eIpwWB2B0qE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
        "\n",
        "assistant = AssistantAgent(name=\"Developer\", system_message=\"You are a Python developer.\")\n",
        "reviewer = AssistantAgent(name=\"Reviewer\", system_message=\"You review code quality.\")\n",
        "\n",
        "user = UserProxyAgent(name=\"User\")\n",
        "\n",
        "# Define a group chat of agents\n",
        "groupchat = GroupChat(agents=[user, assistant, reviewer], messages=[], max_round=3)\n",
        "manager = GroupChatManager(groupchat=groupchat)\n",
        "\n",
        "# Start the group conversation\n",
        "user.initiate_chat(\n",
        "    manager,\n",
        "    message=\"Write a Python function to calculate factorial and have it reviewed.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "0_f18I1P0tZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}